{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f7d15c",
   "metadata": {},
   "source": [
    "First, create a new conda environment named SOS2025 and install the required packages from requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2329db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\martin\\.conda\\envs\\SOS2025\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.11\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              pkgs/main/win-64::bzip2-1.0.8-h2bbff1b_6\n",
      "  ca-certificates    pkgs/main/win-64::ca-certificates-2025.12.2-haa95532_0\n",
      "  expat              pkgs/main/win-64::expat-2.7.3-h885b0b7_4\n",
      "  libexpat           pkgs/main/win-64::libexpat-2.7.3-h885b0b7_4\n",
      "  libffi             pkgs/main/win-64::libffi-3.4.4-hd77b12b_1\n",
      "  libzlib            pkgs/main/win-64::libzlib-1.3.1-h02ab6af_0\n",
      "  openssl            pkgs/main/win-64::openssl-3.0.18-h543e019_0\n",
      "  pip                pkgs/main/noarch::pip-25.3-pyhc872135_0\n",
      "  python             pkgs/main/win-64::python-3.11.14-h981015d_0\n",
      "  setuptools         pkgs/main/win-64::setuptools-80.9.0-py311haa95532_0\n",
      "  sqlite             pkgs/main/win-64::sqlite-3.51.1-hda9a48d_0\n",
      "  tk                 pkgs/main/win-64::tk-8.6.15-hf199647_0\n",
      "  tzdata             pkgs/main/noarch::tzdata-2025c-he532380_0\n",
      "  ucrt               pkgs/main/win-64::ucrt-10.0.22621.0-haa95532_0\n",
      "  vc                 pkgs/main/win-64::vc-14.3-h2df5915_10\n",
      "  vc14_runtime       pkgs/main/win-64::vc14_runtime-14.44.35208-h4927774_10\n",
      "  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.44.35208-ha6b5a95_10\n",
      "  wheel              pkgs/main/win-64::wheel-0.45.1-py311haa95532_0\n",
      "  xz                 pkgs/main/win-64::xz-5.6.4-h4754444_1\n",
      "  zlib               pkgs/main/win-64::zlib-1.3.1-h02ab6af_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate SOS2025\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!conda create -n SOS2025 python=3.11 -y\n",
    "#!conda activate SOS2025\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5122654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Starvers for the provenance documentation. \n",
    "# Import the libraries required for the exercise, e.g., pandas, numpy, scipy, matplotlib, seaborn and scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import typing\n",
    "import requests\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from starvers.starvers import TripleStoreEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79408d3",
   "metadata": {},
   "source": [
    "## Graph-based documentation preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831a95c",
   "metadata": {},
   "source": [
    "**!!!IMPORTANT!!!**\n",
    "\n",
    "Everytime you work on this notebook, enter your student ID in the `executed_by` variable so that the cell executions are accredited to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a02423",
   "metadata": {},
   "outputs": [],
   "source": [
    "executed_by ='stud-id_01634081'  # Replace the digits after \"id_\" with your own student ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2160a7",
   "metadata": {},
   "source": [
    "Set your group and student IDs. Do this only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16721334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group id for this project\n",
    "group_id = '21'  # Replace the digits with your group id\n",
    "\n",
    "# Students working on this notebook\n",
    "student_a = 'stud-id_01634081'  # Replace the digits after \"id_\" with student A's student ID\n",
    "student_b = 'stud-id_00753306'  # Replace the digits after \"id_\" with student B's student ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb927186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roles. Don't change these values.\n",
    "code_writer_role = 'code_writer'\n",
    "code_executor_role = 'code_executor'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e253f6",
   "metadata": {},
   "source": [
    "Setup the starvers API for logging your steps into our server-sided graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4195fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_endpoint = \"https://starvers.ec.tuwien.ac.at/BI2025\"\n",
    "post_endpoint = \"https://starvers.ec.tuwien.ac.at/BI2025/statements\"\n",
    "engine = TripleStoreEngine(get_endpoint, post_endpoint, skip_connection_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cee91",
   "metadata": {},
   "source": [
    "Use these prefixes in your notebooks. You can extend this dict with your prefixes of additional ontologies that you use in this notebook. Replace 00 with your group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e6f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = {\n",
    "    'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
    "    'foaf': 'http://xmlns.com/foaf/0.1/',\n",
    "    'prov': 'http://www.w3.org/ns/prov#',\n",
    "    'sc': 'https://schema.org/',\n",
    "    'cr': 'http://mlcommons.org/croissant/',\n",
    "    'mls': 'http://www.w3.org/ns/mls#',\n",
    "    'mlso': 'http://w3id.org/mlso',\n",
    "    'siu': 'https://si-digital-framework.org/SI/units/',\n",
    "    'siq': 'https://si-digital-framework.org/SI/quantities/',\n",
    "    'qudt': 'http://qudt.org/schema/qudt/',\n",
    "    '': f'https://starvers.ec.tuwien.ac.at/SOS2025/{group_id}/',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970468d",
   "metadata": {},
   "source": [
    "Ontologies to use\n",
    "* Provenance of the experiment process\n",
    "    * PROV-O: \n",
    "        * doc: https://www.w3.org/TR/prov-o/\n",
    "        * serialization: https://www.w3.org/ns/prov-o\n",
    "* Data used and created\n",
    "    * schema.org - Dataset: \n",
    "        * doc: https://schema.org/Dataset\n",
    "        * serialization: https://schema.org/version/latest/schemaorg-current-https.ttl\n",
    "    * Crossaint\n",
    "        * doc: https://docs.mlcommons.org/croissant/docs/croissant-spec.html\n",
    "        * serialization: https://github.com/mlcommons/croissant/blob/main/docs/croissant.ttl\n",
    "* ML experiments performed\n",
    "    * MLSO: \n",
    "        * doc: https://github.com/dtai-kg/MLSO\n",
    "        * doc: https://dtai-kg.github.io/MLSO/#http://w3id.org/\n",
    "        * serialization: https://dtai-kg.github.io/MLSO/ontology.ttl\n",
    "* Measurements, Metrics, Units\n",
    "    * QUDT\n",
    "        * doc:https://qudt.org/\n",
    "        * doc: https://github.com/qudt/qudt-public-repo\n",
    "        * serialization: https://github.com/qudt/qudt-public-repo/blob/main/src/main/rdf/schema/SCHEMA_QUDT.ttl\n",
    "    * SI Digital Framework\n",
    "        * doc: https://github.com/TheBIPM/SI_Digital_Framework/blob/main/SI_Reference_Point/docs/README.md\n",
    "        * doc: https://si-digital-framework.org/\n",
    "        * doc: https://si-digital-framework.org/SI\n",
    "        * serialization: https://github.com/TheBIPM/SI_Digital_Framework/blob/main/SI_Reference_Point/TTL/si.ttl\n",
    "    * Quantities and Units\n",
    "        * doc: https://www.omg.org/spec/Commons\n",
    "        * serialization: https://www.omg.org/spec/Commons/QuantitiesAndUnits.ttl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62393d",
   "metadata": {},
   "source": [
    "Use this function to record execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f08ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def now() -> str:\n",
    "    \"\"\"\n",
    "    Returns the current time in ISO 8601 format with UTC timezone in the following format:\n",
    "    YYYY-MM-DDTHH:MM:SS.sssZ\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now(datetime.timezone.utc)\n",
    "    timestamp_formated = timestamp.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]  +\"Z\"\n",
    "\n",
    "    return timestamp_formated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a1605",
   "metadata": {},
   "source": [
    "Register yourself in the Knowledge Graph using ProvO. Change the given name, family name and immatriculation number to reflect your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4080a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ontologies used: foaf, prov, IAO\n",
    "reigstration_triples_a = [\n",
    "f':{student_a} rdf:type foaf:Person .',\n",
    "f':{student_a} rdf:type prov:Agent .',\n",
    "f':{student_a} foaf:givenName \"Martin\" .',\n",
    "f':{student_a} foaf:familyName \"Kowarik\" .',\n",
    "f':{student_a} <http://vivoweb.org/ontology/core#identifier> :{student_a} .',\n",
    "f':{student_a} rdf:type <http://purl.obolibrary.org/obo/IAO_0000578> .',\n",
    "f':{student_a} <http://www.w3.org/2000/01/rdf-schema#label> \"Immatriculation number\" .',\n",
    "f':{student_a} <http://purl.obolibrary.org/obo/IAO_0000219> \"01634081\"^^xsd:string .',\n",
    "]\n",
    "\n",
    "reigstration_triples_b = [\n",
    "f':{student_b} rdf:type foaf:Person .',\n",
    "f':{student_b} rdf:type prov:Agent .',\n",
    "f':{student_b} foaf:givenName \"Matthias\" .',\n",
    "f':{student_b} foaf:familyName \"Frenzl\" .',\n",
    "f':{student_b} <http://vivoweb.org/ontology/core#identifier> :{student_b} .',\n",
    "f':{student_b} rdf:type <http://purl.obolibrary.org/obo/IAO_0000578> .',\n",
    "f':{student_b} <http://www.w3.org/2000/01/rdf-schema#label> \"Immatriculation number\" .',\n",
    "f':{student_b} <http://purl.obolibrary.org/obo/IAO_0000219> \"00753306\"^^xsd:string .',\n",
    "]\n",
    "\n",
    "role_triples = [\n",
    "    f':{code_writer_role} rdf:type prov:Role .',\n",
    "    f':{code_executor_role} rdf:type prov:Role .',\n",
    "]\n",
    "\n",
    "\n",
    "engine.insert(reigstration_triples_a, prefixes=prefixes)\n",
    "engine.insert(reigstration_triples_b, prefixes=prefixes)\n",
    "engine.insert(role_triples, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fc1dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c479ed4",
   "metadata": {},
   "source": [
    "**What not do do**\n",
    "\n",
    "Do not use [blank nodes](https://www.w3.org/wiki/BlankNodes).\n",
    "\n",
    "PROV-O uses blank nodes to connect multiple elements with each other.\n",
    "Such blank nodes (such as _:association) should not be used.\n",
    "Instead, assign a fixed node ID such as\n",
    ":5119fcd7-b571-41e0-9464-a37c7be0f574 by generating them outside of the\n",
    "notebook.\n",
    "We suggest that, for each setting where such a blank node is needed to\n",
    "connect multiple elements, you create a unique hash (using uuid.uuid4())\n",
    "and keep this as hard-coded identifier for the blank node. The template\n",
    "notebook contains examples of this. Do *not* use these provided values,\n",
    "as otherwise, your provenance documentations will all be connected via\n",
    "these identifiers!\n",
    "Also, do not generate them dynamically in every cell execution, e.g. by\n",
    "using uuid.uuid4() in a cell. This would generate many new linking nodes\n",
    "for connecting the same elements.\n",
    "Compute one for each node (cell) where you need them and make sure to\n",
    "use the same one on each re-execution of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890a782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_path = os.path.join(\"data\", \"datasets\", \"weather\")\n",
    "cyclists_data_path = os.path.join(\"data\", \"datasets\", \"cyclists\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36ba8220",
   "metadata": {},
   "source": [
    "## Machine-actionable Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8eaeadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': ['https://schema.org/',\n",
       "  {'ml': 'https://mlcommons.org/croissant/'}],\n",
       " '@type': 'Dataset',\n",
       " '@id': 'https://www.openml.org/d/1492',\n",
       " 'name': 'one-hundred-plants-shape',\n",
       " 'description': 'Leaf shape descriptors for one-hundred plant species. Each instance is a 64-element shape feature vector with a class label for species.',\n",
       " 'creator': {'@type': 'Organization', 'name': 'OpenML Contributors'},\n",
       " 'keywords': ['leaf shape',\n",
       "  'plant classification',\n",
       "  '64-dimensional vectors',\n",
       "  'multiclass'],\n",
       " 'license': 'Open Data Commons Attribution License',\n",
       " 'temporalCoverage': 'N/A',\n",
       " 'spatialCoverage': 'N/A',\n",
       " 'distribution': {'@type': 'DataDownload',\n",
       "  'contentUrl': 'https://www.openml.org/data/v1/download/1592284/one-hundred-plants-shape.arff',\n",
       "  'encodingFormat': 'application/arff'},\n",
       " 'ml:recordSet': {'@type': 'ml:RecordSet',\n",
       "  'ml:field': [{'@type': 'ml:Field',\n",
       "    'name': 'ShapeFeature1',\n",
       "    'description': 'First component of the 64-dimensional shape descriptor',\n",
       "    'dataType': 'number'},\n",
       "   {'@type': 'ml:Field',\n",
       "    'name': 'ShapeFeature64',\n",
       "    'description': 'Last component of the 64-dimensional shape descriptor',\n",
       "    'dataType': 'number'},\n",
       "   {'@type': 'ml:Field',\n",
       "    'name': 'Class',\n",
       "    'description': 'Plant species label',\n",
       "    'dataType': 'string',\n",
       "    'ml:semanticType': 'https://schema.org/Text'}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"@context\": [\n",
    "    \"https://schema.org/\",\n",
    "    {\n",
    "      \"ml\": \"https://mlcommons.org/croissant/\"\n",
    "    }\n",
    "  ],\n",
    "  \"@type\": \"Dataset\",\n",
    "  \"@id\": \"https://www.openml.org/d/1492\",\n",
    "  \"name\": \"one-hundred-plants-shape\",\n",
    "  \"description\": \"Leaf shape descriptors for one-hundred plant species. Each instance is a 64-element shape feature vector with a class label for species.\",\n",
    "  \"creator\": {\n",
    "    \"@type\": \"Organization\",\n",
    "    \"name\": \"OpenML Contributors\"\n",
    "  },\n",
    "  \"keywords\": [\n",
    "    \"leaf shape\",\n",
    "    \"plant classification\",\n",
    "    \"64-dimensional vectors\",\n",
    "    \"multiclass\"\n",
    "  ],\n",
    "  \"license\": \"Open Data Commons Attribution License\",\n",
    "  \"temporalCoverage\": \"N/A\",\n",
    "  \"spatialCoverage\": \"N/A\",\n",
    "  \"distribution\": {\n",
    "    \"@type\": \"DataDownload\",\n",
    "    \"contentUrl\": \"https://www.openml.org/data/v1/download/1592284/one-hundred-plants-shape.arff\",\n",
    "    \"encodingFormat\": \"application/arff\"\n",
    "  },\n",
    "  \"ml:recordSet\": {\n",
    "    \"@type\": \"ml:RecordSet\",\n",
    "    \"ml:field\": [\n",
    "      {\n",
    "        \"@type\": \"ml:Field\",\n",
    "        \"name\": \"ShapeFeature1\",\n",
    "        \"description\": \"First component of the 64-dimensional shape descriptor\",\n",
    "        \"dataType\": \"number\"\n",
    "      },\n",
    "      {\n",
    "        \"@type\": \"ml:Field\",\n",
    "        \"name\": \"ShapeFeature64\",\n",
    "        \"description\": \"Last component of the 64-dimensional shape descriptor\",\n",
    "        \"dataType\": \"number\"\n",
    "      },\n",
    "      {\n",
    "        \"@type\": \"ml:Field\",\n",
    "        \"name\": \"Class\",\n",
    "        \"description\": \"Plant species label\",\n",
    "        \"dataType\": \"string\",\n",
    "        \"ml:semanticType\": \"https://schema.org/Text\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee069d",
   "metadata": {},
   "source": [
    "## Business Understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ee88389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Business Understanding Phase\n",
    "\n",
    "business_understanding_phase_executor = [\n",
    "f':business_understanding_phase rdf:type prov:Activity .',\n",
    "f':business_understanding_phase rdfs:label \"Business Understanding Phase\" .', ## Phase 1: Business Understanding\n",
    "]\n",
    "engine.insert(business_understanding_phase_executor, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31dc8a3a-708a-4992-a076-038c53338e89",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bd9643d1e26a8dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "data_src_and_scenario_comment = \"\"\"\n",
    "...Data source and Scenario description...\n",
    "\"\"\"\n",
    "\n",
    "business_objectives_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "business_success_criteria_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "data_mining_goals_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "data_mining_success_criteria_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "ai_risk_aspects_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bu_ass_uuid_executor = \"bb6a40f9-9d92-4f9f-bbd2-b65ef6a82da2\" # Generate once\n",
    "business_understanding_executor = [\n",
    "f':business_understanding rdf:type prov:Activity .',\n",
    "f':business_understanding sc:isPartOf :business_understanding_phase .', # Connect Activity to Parent Business Understanding Phase Activity\n",
    "f':business_understanding prov:qualifiedAssociation :{bu_ass_uuid_executor} .',\n",
    "f':{bu_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "f':{bu_ass_uuid_executor} rdf:type prov:Association .',\n",
    "f':{bu_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(business_understanding_executor, prefixes=prefixes)\n",
    "\n",
    "\n",
    "business_understanding_data_executor = [\n",
    "# 1a\n",
    "f':bu_data_source_and_scenario rdf:type prov:Entity .',\n",
    "f':bu_data_source_and_scenario prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_data_source_and_scenario rdfs:label \"1a Data Source and Scenario\" .',\n",
    "f':bu_data_source_and_scenario rdfs:comment \"\"\"{data_src_and_scenario_comment}\"\"\" .',\n",
    "# 1b\n",
    "f':bu_business_objectives rdf:type prov:Entity .',\n",
    "f':bu_business_objectives prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_business_objectives rdfs:label \"1b Business Objectives\" .',\n",
    "f':bu_business_objectives rdfs:comment \"\"\"{business_objectives_comment}\"\"\" .',\n",
    "# 1c\n",
    "f':bu_business_success_criteria rdf:type prov:Entity .',\n",
    "f':bu_business_success_criteria prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_business_success_criteria rdfs:label \"1c Business Success Criteria\" .',\n",
    "f':bu_business_success_criteria rdfs:comment \"\"\"{business_success_criteria_comment}\"\"\" .',\n",
    "# 1d\n",
    "f':bu_data_mining_goals rdf:type prov:Entity .',\n",
    "f':bu_data_mining_goals prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_data_mining_goals rdfs:label \"1d Data Mining Goals\" .',\n",
    "f':bu_data_mining_goals rdfs:comment \"\"\"{data_mining_goals_comment}\"\"\" .',\n",
    "# 1e\n",
    "f':bu_data_mining_success_criteria rdf:type prov:Entity .',\n",
    "f':bu_data_mining_success_criteria prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_data_mining_success_criteria rdfs:label \"1e Data Mining Success Criteria\" .',\n",
    "f':bu_data_mining_success_criteria rdfs:comment \"\"\"{data_mining_success_criteria_comment}\"\"\" .',\n",
    "# 1f\n",
    "f':bu_ai_risk_aspects rdf:type prov:Entity .',\n",
    "f':bu_ai_risk_aspects prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_ai_risk_aspects rdfs:label \"1f AI risk aspects\" .',\n",
    "f':bu_ai_risk_aspects rdfs:comment \"\"\"{ai_risk_aspects_comment}\"\"\" .',\n",
    "\n",
    "]\n",
    "engine.insert(business_understanding_data_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae9b28",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce717fb",
   "metadata": {},
   "source": [
    "The following pseudo-code & pseudo-documentation may be used as a hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "449cc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Data Understanding Phase\n",
    "\n",
    "business_understanding_phase_executor = [\n",
    "f':data_understanding_phase rdf:type prov:Activity .',\n",
    "f':data_understanding_phase rdfs:label \"Data Understanding Phase\" .', \n",
    "]\n",
    "engine.insert(business_understanding_phase_executor, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "247a9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.000579  0.000609  0.000551  0.000554  0.000603  0.000614  0.000611   \n",
       "1  0.000630  0.000661  0.000719  0.000651  0.000643  0.000640  0.000646   \n",
       "2  0.000616  0.000615  0.000606  0.000568  0.000558  0.000552  0.000551   \n",
       "3  0.000613  0.000569  0.000564  0.000607  0.000643  0.000647  0.000663   \n",
       "4  0.000599  0.000552  0.000558  0.000569  0.000616  0.000639  0.000631   \n",
       "\n",
       "         V8        V9       V10  ...       V56       V57       V58       V59  \\\n",
       "0  0.000611  0.000611  0.000594  ...  0.000533  0.000555  0.000565  0.000581   \n",
       "1  0.000624  0.000584  0.000546  ...  0.000520  0.000533  0.000564  0.000596   \n",
       "2  0.000552  0.000531  0.000530  ...  0.000590  0.000589  0.000566  0.000575   \n",
       "3  0.000658  0.000635  0.000600  ...  0.000536  0.000549  0.000542  0.000566   \n",
       "4  0.000634  0.000639  0.000596  ...  0.000543  0.000557  0.000562  0.000558   \n",
       "\n",
       "        V60       V61       V62       V63       V64  Class  \n",
       "0  0.000597  0.000625  0.000624  0.000617  0.000614     13  \n",
       "1  0.000623  0.000642  0.000661  0.000671  0.000667     13  \n",
       "2  0.000618  0.000543  0.000592  0.000607  0.000602     13  \n",
       "3  0.000592  0.000601  0.000609  0.000614  0.000603     13  \n",
       "4  0.000591  0.000608  0.000613  0.000610  0.000594     13  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "cyclists_data_path = os.path.join(\"data\", \"datasets\", \"cyclists\")\n",
    "load_cycling_data_code_writer = student_a\n",
    "def load_cycling_data()-> pd.DataFrame:\n",
    "\n",
    "    ### Load your data\n",
    "    data, meta = arff.loadarff(\"php0FyS2T.arff\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Decode byte strings (ARFF often uses bytes)\n",
    "    for col in df.select_dtypes([object]).columns:\n",
    "        df[col] = df[col].str.decode(\"utf-8\")\n",
    "\n",
    "    df.head()\n",
    "    \n",
    "    def create_date_index(dataframe: pd.DataFrame):\n",
    "    # create year, month, and day columns\n",
    "        index_cols = ['year', 'month', 'day']\n",
    "        dataframe['date'] = pd.to_datetime(dataframe['date'], dayfirst=False, yearfirst=True)\n",
    "        dataframe['year'] = dataframe['date'].dt.year\n",
    "        dataframe['month'] = dataframe['date'].dt.month\n",
    "        dataframe['day'] = dataframe['date'].dt.day\n",
    "\n",
    "        dataframe.sort_values(index_cols, ascending = [True for _ in index_cols], inplace = True)\n",
    "        dataframe.set_index(index_cols, inplace = True)\n",
    "        dataframe.index.set_names(index_cols, inplace = True)\n",
    "        return dataframe\n",
    "\n",
    "    #loaded_data = raw_data\n",
    "    #loaded_data['day_of_week'] = pd.to_datetime(loaded_data['date']).dt.day_name()\n",
    "    df[\"Class\"] = pd.to_numeric(df[\"Class\"], errors=\"raise\")\n",
    "    loaded_data = df\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "start_time_ld = now()\n",
    "data = load_cycling_data()\n",
    "end_time_ld = now()\n",
    "\n",
    "display(data.head())\n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "# Now document the raw data and the loaded data using appropriate ontologies.\n",
    "\n",
    "# Always add these triples for every activity to define the executor!\n",
    "ld_ass_uuid_executor = \"b8bac193-c4e6-4e31-9134-b23e001e279c\" # Generate once\n",
    "load_cycling_data_executor = [\n",
    "    f':load_cycling_data prov:qualifiedAssociation :{ld_ass_uuid_executor} .',\n",
    "    f':{ld_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{ld_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{ld_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(load_cycling_data_executor, prefixes=prefixes)\n",
    "\n",
    "ld_ass_uuid_writer = \"c600e15c-87a9-4e2a-be85-b6c2a3014210\" # Generate once\n",
    "ld_report = \"\"\"\n",
    "Load all cycling data and create a hierarchical index (year, month, day). \n",
    "\"\"\"\n",
    "load_cycling_data_activity = [\n",
    "    ':load_cycling_data rdf:type prov:Activity .',\n",
    "    ':load_cycling_data sc:isPartOf :data_understanding_phase .',\n",
    "    ':load_cycling_data rdfs:comment \\'Data Understanding\\' .',\n",
    "    f':load_cycling_data rdfs:comment \"\"\"{ld_report}\"\"\" .', \n",
    "    f':load_cycling_data prov:startedAtTime \"{start_time_ld}\"^^xsd:dateTime .',\n",
    "    f':load_cycling_data prov:endedAtTime \"{end_time_ld}\"^^xsd:dateTime .',\n",
    "    f':load_cycling_data prov:qualifiedAssociation :{ld_ass_uuid_writer} .',\n",
    "    f':{ld_ass_uuid_writer} prov:agent :{load_cycling_data_code_writer} .',\n",
    "    f':{ld_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{ld_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    # INPUT of activity\n",
    "    ':load_cycling_data prov:used :raw_data .',\n",
    "    ':load_cycling_data prov:used :raw_data_path .',\n",
    "    ':raw_data rdf:type prov:Entity .',\n",
    "    ':raw_data_path rdf:type prov:Entity .',\n",
    "    ':raw_data prov:wasDerivedFrom :raw_data_path .',\n",
    "    # OUTPUT of activity\n",
    "    ':data rdf:type prov:Entity .',\n",
    "    ':data prov:wasGeneratedBy :load_cycling_data .',\n",
    "    ':data prov:wasDerivedFrom :raw_data .',\n",
    "]\n",
    "engine.insert(load_cycling_data_activity, prefixes=prefixes)\n",
    "\n",
    "# Further descibe the raw data using Croissant\n",
    "raw_data_triples = [\n",
    "    ':raw_data rdf:type sc:Dataset .',\n",
    "    ':raw_data sc:name \\'Cyclist data set\\' .',\n",
    "    ':raw_data sc:description \\'Describe the data set.\\' .',\n",
    "    # Continue with futher information about the dataset...\n",
    "    ':cyclists_csv rdf:type cr:FileObject .',\n",
    "    ':cyclists_csv sc:name \\'cyclists.csv\\' .',\n",
    "    ':cyclists_csv sc:encodingFormat \\'text/csv\\' .',\n",
    "    ':raw_data sc:distribution :cyclists_csv .',\n",
    "    # Continue with further information about the distribution...\n",
    "    ':raw_recordset rdf:type cr:RecordSet .',\n",
    "    ':raw_recordset sc:name \\'Table of cycling data per day\\' .',\n",
    "    ':raw_recordset cr:source :cyclists_csv .',\n",
    "    ':raw_data cr:recordSet :raw_recordset .',\n",
    "    # Continue with further information about the recordset...\n",
    "    ':raw_recordset cr:field :field_date .',\n",
    "    ':raw_recordset cr:field :field_number .',\n",
    "    ':field_date rdf:type cr:Field .',\n",
    "    ':field_date sc:name \\'date\\' .',\n",
    "    ':field_date sc:description \\'This is a date field of...\\' .',\n",
    "    ':field_date cr:dataType xsd:dateTime .',\n",
    "    # Continue with futher information about the field...\n",
    "    ':field_number rdf:type cr:Field .',\n",
    "    ':field_number sc:name \\'number\\' .',\n",
    "    ':field_number sc:description \\'This field describes..\\' .',\n",
    "    ':field_number cr:dataType xsd:integer .',\n",
    "    # Continue with futher fields...\n",
    "]\n",
    "engine.insert(raw_data_triples, prefixes=prefixes)\n",
    "\n",
    "# Also the output of the load activity is a dataset that can be described with Croissant\n",
    "data_triples = [\n",
    "    ':data rdf:type sc:Dataset .',\n",
    "    # ...\n",
    "    ':recordset rdf:type cr:RecordSet .',\n",
    "    # ...\n",
    "    ':data cr:recordSet :recordset .',\n",
    "    # ...\n",
    "    # Fields can also be reused\n",
    "    ':recordset cr:field :field_date .',\n",
    "    ':recordset cr:field :field_number .',\n",
    "    # The loaded data has additional fields\n",
    "    ':recordset cr:field :field_day_of_week .',\n",
    "    ':field_day_of_week rdf:type cr:Field .',\n",
    "    ':field_day_of_week sc:name \\'day_of_week\\' .',\n",
    "    ':field_day_of_week sc:description \\'Day of week description\\' .',\n",
    "    ':field_day_of_week cr:dataType xsd:string .',\n",
    "    # This is not actually a field in the dataframe but below demonstrates how units may be used\n",
    "    ':recordset cr:field :field_temp .', \n",
    "    ':field_temp rdf:type cr:Field .',\n",
    "    ':field_temp sc:name \\'temperature\\' .',\n",
    "    ':field_temp sc:description \\'Description Temperature\\' .',\n",
    "    ':field_temp cr:dataType xsd:double .',\n",
    "]\n",
    "engine.insert(data_triples, prefixes=prefixes)\n",
    "\n",
    "# Also add the units to the fields\n",
    "units_triples = [\n",
    "    ':field_number qudt:unit qudt:CountingUnit .',\n",
    "    ':field_temp qudt:unit siu:degree_Celsius .',\n",
    "]\n",
    "engine.insert(units_triples, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93316bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       float64\n",
       "V2       float64\n",
       "V3       float64\n",
       "V4       float64\n",
       "V5       float64\n",
       "          ...   \n",
       "V61      float64\n",
       "V62      float64\n",
       "V63      float64\n",
       "V64      float64\n",
       "Class      int64\n",
       "Length: 65, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.head()\n",
    "#data.shape\n",
    "data.dtypes\n",
    "#data.agg([\"min\", \"max\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6c7668c",
   "metadata": {},
   "source": [
    "number of instances\t1600\n",
    "number of features\t65\n",
    "number of classes\t100\n",
    "number of missing values\t0\n",
    "number of instances with missing values\t0\n",
    "number of numeric features\t64\n",
    "number of symbolic features\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0580e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'number'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\martin\\.conda\\envs\\SOS2025\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'number'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     39\u001b[39m start_time_co = now()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m outliers_report = \u001b[43mcheck_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m end_time_co = now()\n\u001b[32m     43\u001b[39m start_time_ho = now()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mcheck_outliers\u001b[39m\u001b[34m(data, threshold, columns)\u001b[39m\n\u001b[32m     10\u001b[39m tmp = tmp.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     values = \u001b[43mtmp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     15\u001b[39m     mean = values.mean()\n\u001b[32m     16\u001b[39m     std = values.std()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\martin\\.conda\\envs\\SOS2025\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\martin\\.conda\\envs\\SOS2025\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'number'"
     ]
    }
   ],
   "source": [
    "check_outliers_code_writer = student_a\n",
    "\n",
    "def check_outliers(data: pd.DataFrame, threshold=3.0, columns=('number',)) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    ### DIRTY HACK\n",
    "    ### REPLACE WITH YOUR ACTUAL OUTLIER CHECKING\n",
    "\n",
    "    tmp = data.copy()\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "\n",
    "    for col in columns:\n",
    "        values = tmp[col].astype(float)\n",
    "\n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "\n",
    "        if std == 0 or np.isnan(std):\n",
    "            results[col] = []\n",
    "            continue\n",
    "\n",
    "        z_scores = (values - mean) / std\n",
    "\n",
    "        mask = np.abs(z_scores) > threshold\n",
    "        outliers = values[mask].index\n",
    "\n",
    "        outlier_info = [\n",
    "            {\n",
    "                'index': int(idx),\n",
    "                'z_score': float(z_scores.loc[idx])\n",
    "            }\n",
    "            for idx in outliers\n",
    "        ]\n",
    "\n",
    "        results[col] = outlier_info\n",
    "\n",
    "    return results\n",
    "\n",
    "start_time_co = now()\n",
    "outliers_report = check_outliers(data, threshold=2.2)\n",
    "end_time_co = now()\n",
    "\n",
    "start_time_ho = now()\n",
    "print(outliers_report)\n",
    "end_time_ho = now()\n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "# There are three steps involved in this process:\n",
    "# 1. activity creates a figure, report etc. => in this case a report\n",
    "# 2. activity inspects the outcome and derives decisions => in this case to remove the outliers that were found\n",
    "# 3. activity follows up on the decision by changing the data => will be done in the data preparation phase\n",
    "\n",
    "# 1. Activty: Checking for outliers and creating the report\n",
    "co_ass_uuid_executor = \"15085e9d-15f1-4727-9b6e-776dd07fcd08\"\n",
    "check_outliers_executor = [\n",
    "    f':check_outliers prov:qualifiedAssociation :{co_ass_uuid_executor} .',\n",
    "    f':{co_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{co_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{co_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(check_outliers_executor, prefixes=prefixes)\n",
    "\n",
    "co_ass_uuid_writer = \"cd4970df-9f40-4bb1-8fad-e4dc4fcdd284\"\n",
    "co_comment = \"\"\"\n",
    "Identifying outliers with a dirty hack that uses the z-score of each row within in column and reports all values \n",
    "with a z-score higher than 2.2 as an outlier, which is not a reasonable threshold but used here to avoid not \n",
    "finding any outliers for demonstration purposes.\n",
    "\"\"\"\n",
    "check_outliers_activity = [\n",
    "    ':check_outliers rdf:type prov:Activity .',\n",
    "    ':check_outliers sc:isPartOf :data_understanding_phase .',\n",
    "    ':check_outliers rdfs:comment \\'Data Understanding\\' .',\n",
    "    f':check_outliers rdfs:comment \"\"\"{co_comment}\"\"\" .', \n",
    "    f':check_outliers prov:startedAtTime \"{start_time_co}\"^^xsd:dateTime .',\n",
    "    f':check_outliers prov:endedAtTime \"{end_time_co}\"^^xsd:dateTime .',\n",
    "    f':check_outliers prov:qualifiedAssociation :{co_ass_uuid_writer} .',\n",
    "    f':{co_ass_uuid_writer} prov:agent :{check_outliers_code_writer} .',\n",
    "    f':{co_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{co_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    ':check_outliers prov:used :data .',\n",
    "    ':outlier_report rdf:type prov:Entity .',\n",
    "    f':outlier_report rdfs:comment \"\"\"{json.dumps(outliers_report, indent=2)}\"\"\" .',\n",
    "    ':outlier_report prov:wasGeneratedBy :check_outliers .',\n",
    "    # ...\n",
    "]\n",
    "engine.insert(check_outliers_activity, prefixes=prefixes)\n",
    "\n",
    "# 2. Activity: Inspecting the report and taking a decision on what to do\n",
    "ior_ass_uuid_executor = \"6eaa2c0a-e592-4d85-b37f-d695844910cf\"\n",
    "ior_comment = \"\"\"\n",
    "After inspecting the report the decision has been made to remove all outliers that were identfied for demonstration purpose3\n",
    "\"\"\"\n",
    "inspect_outlier_report_executor = student_a\n",
    "inspect_outlier_report_activity = [\n",
    "    ':inspect_outlier_report rdf:type prov:Activity .',\n",
    "    ':inspect_outlier_report rdfs:comment \\'Data Understanding\\' .',\n",
    "    f':inspect_outlier_report rdfs:comment \"\"\"{co_comment}\"\"\" .', \n",
    "    f':inspect_outlier_report prov:startedAtTime \"{start_time_co}\"^^xsd:dateTime .',\n",
    "    f':inspect_outlier_report prov:endedAtTime \"{end_time_co}\"^^xsd:dateTime .',\n",
    "    f':inspect_outlier_report prov:qualifiedAssociation :{ior_ass_uuid_executor} .',\n",
    "    f':{ior_ass_uuid_executor} prov:agent :{inspect_outlier_report_executor} .',\n",
    "    f':{ior_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{ior_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "    ':inspect_outlier_report prov:used :outlier_report .',\n",
    "    ':outlier_decision rdf:type prov:Entity .',\n",
    "    f':outlier_decision rdfs:comment \"\"\"Removing all outliers for demonstration purposes.\"\"\" .',\n",
    "    ':outlier_decision prov:wasGeneratedBy :inspect_outlier_report .',\n",
    "    # ...\n",
    "]\n",
    "engine.insert(inspect_outlier_report_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94dfb7-328c-432b-b7e7-1f66f03eabca",
   "metadata": {},
   "source": [
    "**Continue with other tasks of the Data Understanding phase such as checking the distribution, skewness, plausibility of values, etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b4793-5fad-4c9a-89dd-abd662f916b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781e016-c770-43d2-871a-f4f4ab7378b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16349e3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d290a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Data Preparation Phase\n",
    "\n",
    "data_preparation_phase_executor = [\n",
    "f':data_preparation_phase rdf:type prov:Activity .',\n",
    "f':data_preparation_phase rdfs:label \"Data Preparation Phase\" .', \n",
    "]\n",
    "engine.insert(data_preparation_phase_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d076f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_outliers_code_writer = student_b\n",
    "def handle_outliers(df:pd.DataFrame, outliers_report: dict) -> pd.DataFrame:\n",
    "    # REMOVE OUTLIERS\n",
    "    return df\n",
    "\n",
    "start_time_td = now()\n",
    "handle_outliers(data, outliers_report)\n",
    "end_time_td = now()\n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "# This is the continuation of the example from the Data Understanding phase above.\n",
    "# There are three steps involved in this process:\n",
    "# 1. activity creates a figure, report etc. => already done in data understanding phase\n",
    "# 2. activity inspects the outcome and derives decisions => already done in data understanding phase\n",
    "# 3. activity follows up on the decision by changing the data => in this case by removing the the outliers that were found\n",
    "\n",
    "ro_ass_uuid_executor = \"ec7e81e1-86ea-475a-a8d4-c7d8ee535488\"\n",
    "handle_outliers_executor = [\n",
    "    f':handle_outliers prov:qualifiedAssociation :{ro_ass_uuid_executor} .',\n",
    "    f':{ro_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{ro_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{ro_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(handle_outliers_executor, prefixes=prefixes)\n",
    "\n",
    "td_ass_uuid_writer = \"1405f15a-3545-4014-a962-637f3c10a137\"\n",
    "td_comment = \"\"\"\n",
    "Removing all outliers that were identifying in the Data Understanding Phase.\n",
    "\"\"\"\n",
    "handle_outliers_activity = [\n",
    "    ':handle_outliers rdf:type prov:Activity .',\n",
    "    ':handle_outliers sc:isPartOf :data_preparation_phase .',\n",
    "    ':handle_outliers rdfs:comment \\'Data Preparation\\' .', \n",
    "    f':handle_outliers rdfs:comment \"\"\"{td_comment}\"\"\" .', \n",
    "    f':handle_outliers prov:startedAtTime \"{start_time_td}\"^^xsd:dateTime .',\n",
    "    f':handle_outliers prov:endedAtTime \"{end_time_td}\"^^xsd:dateTime .',\n",
    "    f':handle_outliers prov:qualifiedAssociation :{td_ass_uuid_writer} .',\n",
    "    f':{td_ass_uuid_writer} prov:agent :{handle_outliers_code_writer} .',\n",
    "    f':{td_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{td_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    ':handle_outliers prov:used :data .',\n",
    "    ':handle_outliers prov:used :outlier_decision .',\n",
    "    ':cleaned_data rdf:type prov:Entity .',\n",
    "    ':cleaned_data prov:wasGeneratedBy :handle_outliers .',\n",
    "    ':cleaned_data prov:wasDerivedFrom :data .',\n",
    "]\n",
    "engine.insert(handle_outliers_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100cff7-8fd5-4ba1-8913-b4f1ccdfda35",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8800ce26b8f3e2e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Continue with other tasks of the Data Preparation phase such as binning, scaling etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20b8e8-7d7f-4df5-ba38-62704f020c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447e864-ca19-41de-b61a-e2e73863ad2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0036428-fcdf-4ee8-ad52-424f95024cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your final transformed dataset should also be documented appropriately using Croissant, SI, etc.\n",
    "\n",
    "prepared_data_triples = [\n",
    "    ':prepared_data rdf:type prov:Entity .',\n",
    "    ':prepared_data prov:wasDerivedFrom :cleaned_data .',\n",
    "    ':prepared_data rdf:type sc:Dataset .',\n",
    "    # ....\n",
    "]\n",
    "engine.insert(prepared_data_triples, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c19ebb",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb93dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Modeling Phase\n",
    "\n",
    "modeling_phase_executor = [\n",
    "f':modeling_phase rdf:type prov:Activity .',\n",
    "f':modeling rdfs:label \"Modeling Phase\" .', \n",
    "]\n",
    "engine.insert(modeling_phase_executor, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e78f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SOMToolbox.minisom as som\n",
    "\n",
    "m = 3\n",
    "n = 30\n",
    "learn = data\n",
    "\n",
    "s = som.MiniSom(n, m, learn.shape[1], sigma=.6, learning_rate=0.5)\n",
    "s.train_random(learn.values, 1000, verbose=False)#1000\n",
    "weights = s._weights.reshape(-1, learn.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0483a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const version = '3.8.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n  const BK_RE = /^https:\\/\\/cdn\\.bokeh\\.org\\/bokeh\\/(release|dev)\\/bokeh-/;\n  const PN_RE = /^https:\\/\\/cdn\\.holoviz\\.org\\/panel\\/[^/]+\\/dist\\/panel/i;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, Bokeh, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      const shouldSkip = skip.includes(escaped) || existing_scripts.includes(escaped)\n      const isBokehOrPanel = BK_RE.test(escaped) || PN_RE.test(escaped)\n      const missingOrBroken = Bokeh == null || Bokeh.Panel == null || (Bokeh.version != version && !Bokeh.versions?.has(version)) || Bokeh.versions?.get(version)?.Panel == null;\n      if (shouldSkip && !(isBokehOrPanel && missingOrBroken)) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.5/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.2.min.js\", \"https://cdn.holoviz.org/panel/1.8.5/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false;\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true;\n      root._bokeh_onload_callbacks = [];\n      const bokeh_loaded = Bokeh != null && ((Bokeh.version === version && Bokeh.Panel) || (Bokeh.versions?.has(version) && Bokeh.versions.get(version)?.Panel));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, Bokeh, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n        if (Bokeh != undefined && !reloading) {\n          const NewBokeh = root.Bokeh;\n          if (Bokeh.versions === undefined) {\n            Bokeh.versions = new Map();\n          }\n          if (NewBokeh.version !== Bokeh.version) {\n            Bokeh[NewBokeh.version] = NewBokeh;\n            Bokeh.versions.set(NewBokeh.version, NewBokeh);\n          }\n          root.Bokeh = Bokeh;\n        }\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='7efc41eb-4e41-4d54-88fc-f1766364da85'>\n",
       "  <div id=\"acf56a00-f01c-480b-b32f-a10b11eeaab0\" data-root-id=\"7efc41eb-4e41-4d54-88fc-f1766364da85\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"3e2d9aa0-d37a-4675-8721-3f5012f542c8\":{\"version\":\"3.8.2\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"4b4387a3-3f07-48dc-9d81-bf7e870a4a30\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"ce7c032c-ef6a-47f3-a367-93fd58078242\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"7efc41eb-4e41-4d54-88fc-f1766364da85\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"8c785fa0-b400-47e3-98c9-299ea42486fd\",\"attributes\":{\"plot_id\":\"7efc41eb-4e41-4d54-88fc-f1766364da85\",\"comm_id\":\"fa01f2a7d12e4032b784d52aa42fe613\",\"client_comm_id\":\"d01dae4d2b154d68afa0de91a5269cb4\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"3e2d9aa0-d37a-4675-8721-3f5012f542c8\",\"roots\":{\"7efc41eb-4e41-4d54-88fc-f1766364da85\":\"acf56a00-f01c-480b-b32f-a10b11eeaab0\"},\"root_ids\":[\"7efc41eb-4e41-4d54-88fc-f1766364da85\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(version);\n",
       "    } else if (root.Bokeh.version === version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "7efc41eb-4e41-4d54-88fc-f1766364da85"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"logo-block\">\n",
       "<a href=\"https://holoviews.org\" target=\"_blank\" title=\"HoloViews 1.22.1\">\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC' style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "</a>\n",
       "\n",
       "\n",
       "<a href=\"https://bokeh.org\" target=\"_blank\" title=\"Bokeh 3.8.2\">\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'>\n",
       "  </img>\n",
       "</a>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"float: left; margin-left: 5px; line-height: 15px; cursor: pointer; opacity: 0.7;\"\n",
       "      onmouseover=\"this.style.opacity='1'\"\n",
       "      onmouseout=\"this.style.opacity='0.7'\"\n",
       "      title=\"Extension loaded. This cell output contains code that enables plot interactivity, it should not be removed.\">â“˜</span>\n",
       "</div>\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualizations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSOMToolbox\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msomtoolbox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SOMToolbox\n\u001b[32m      3\u001b[39m sm = SOMToolbox(weights=weights,m=m,n=n,dimension=\u001b[32m8\u001b[39m, input_data=data.loc[\u001b[33m'\u001b[39m\u001b[33m1985\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33m1992\u001b[39m\u001b[33m'\u001b[39m].values)\n\u001b[32m      4\u001b[39m sm._mainview\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\martin\\Downloads\\sos3\\sos3\\git\\sos3\\SOMToolbox\\somtoolbox.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrols\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrollers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MainController\n\u001b[32m     23\u001b[39m hv.extension(\u001b[33m'\u001b[39m\u001b[33mbokeh\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualizations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomplane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComponentPlane\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualizations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DMatrix\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualizations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhithistogram\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HitHist\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\martin\\Downloads\\sos3\\sos3\\git\\sos3\\SOMToolbox\\visualizations\\complane.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisualizations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miVisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisualizationInterface\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontrols\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrollers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComPlaneController\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpanel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpn\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'visualizations'"
     ]
    }
   ],
   "source": [
    "from SOMToolbox.somtoolbox import SOMToolbox\n",
    "\n",
    "sm = SOMToolbox(weights=weights,m=m,n=n,dimension=8, input_data=data.loc['1985':'1992'].values)\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_code_writer = student_a\n",
    "\n",
    "#############################################\n",
    "# Documentation 4a\n",
    "#############################################\n",
    "\n",
    "dma_ass_uuid_writer = \"b3e840ab-ac23-415e-bd9c-6d00bb79c37a\"\n",
    "dma_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "identify_data_mining_algorithm_activity = [\n",
    "    f':define_algorithm rdf:type prov:Activity .',\n",
    "    f':define_algorithm sc:isPartOf :modeling_phase .',\n",
    "    f':define_algorithm rdfs:comment \"\"\"{dma_comment}\"\"\" .',\n",
    "    f':define_algorithm prov:qualifiedAssociation :{dma_ass_uuid_writer} .',\n",
    "    f':{dma_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{dma_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{dma_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # example algorithm definition\n",
    "    f':random_forest_algorithm rdf:type mls:Algorithm .',\n",
    "    f':random_forest_algorithm rdfs:label \"Random Forest Algorithm\" .',\n",
    "\n",
    "    # example implementation\n",
    "    f':random_forrest_classifier_implementation rdf:type mls:Implementation .',\n",
    "    f':random_forrest_classifier_implementation rdfs:label \"Scikit-learn RandomForestClassifier\" .',\n",
    "    f':random_forrest_classifier_implementation mls:implements :random_forest_algorithm .',\n",
    "    f':random_forrest_classifier_implementation prov:wasGeneratedBy :define_algorithm .',\n",
    "\n",
    "    \n",
    "    # you can also define your Evaluation Measures here\n",
    "    \n",
    "    # example evaluation \n",
    "    f':r2_score_measure rdf:type mls:EvaluationMeasure .',\n",
    "    f':r2_score_measure rdfs:label \"R-squared Score\" .',\n",
    "    f':r2_score_measure rdfs:comment \"xxx\" .',\n",
    "    f':r2_score_measure prov:wasGeneratedBy :define_algorithm .',\n",
    "\n",
    "    \n",
    "]\n",
    "engine.insert(identify_data_mining_algorithm_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Documentation 4b\n",
    "#############################################\n",
    "\n",
    "hp_ass_uuid_writer = \"fff582a8-c5cd-4030-978b-9f56b603167c\"\n",
    "hp_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "identify_hp_activity = [\n",
    "    f':identify_hyperparameters rdf:type prov:Activity .',\n",
    "    f':identify_hyperparameters sc:isPartOf :modeling_phase .',\n",
    "    f':identify_hyperparameters rdfs:comment \"\"\"{hp_comment}\"\"\" .',\n",
    "    f':identify_hyperparameters prov:qualifiedAssociation :{hp_ass_uuid_writer} .',\n",
    "    f':{hp_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{hp_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{hp_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # example parameter\n",
    "    f':hp_learning_rate rdf:type mls:HyperParameter .',\n",
    "    f':hp_learning_rate rdfs:label \"Learning Rate\" .',\n",
    "    f':hp_learning_rate rdfs:comment \"...\" .',\n",
    "    f':random_forrest_classifier_implementation mls:hasHyperParameter :hp_learning_rate .',\n",
    "    f':hp_learning_rate prov:wasGeneratedBy :identify_hyperparameters .',\n",
    "\n",
    "    # continue with your identified hyperparameters\n",
    "    \n",
    "]\n",
    "engine.insert(identify_hp_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995966b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame):\n",
    "    #do something\n",
    "    return 'train_set', 'validation_set', 'test_set'\n",
    "\n",
    "#############################################\n",
    "# Documentation 4c\n",
    "#############################################\n",
    "\n",
    "### Define Train/Validation/Test splits\n",
    "split_ass_uuid_writer = \"fb58ae6c-9d58-44c9-ac7e-529111bdf7fc\"\n",
    "split_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "## Use your prepared dataset\n",
    "input_dataset = \":prepared_data\" \n",
    "\n",
    "define_split_activity = [\n",
    "    f':define_data_split rdf:type prov:Activity .',\n",
    "    f':define_data_split sc:isPartOf :modeling_phase .',\n",
    "    f':define_data_split rdfs:comment \"Train/Validation/Test Split Definition\" .',\n",
    "    f':define_data_split rdfs:comment \"\"\"{split_comment}\"\"\" .',\n",
    "    f':define_data_split prov:qualifiedAssociation :{split_ass_uuid_writer} .',\n",
    "    f':{split_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{split_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{split_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    f':define_data_split prov:used {input_dataset} .',\n",
    "    \n",
    "    # Training Set\n",
    "    f':training_set rdf:type sc:Dataset .',\n",
    "    f':training_set rdfs:label \"Training Set\" .',\n",
    "    f':training_set prov:wasGeneratedBy :define_data_split .',\n",
    "    f':training_set prov:wasDerivedFrom {input_dataset} .',\n",
    "    f':training_set rdfs:comment \"Contains xx samples\" .', \n",
    "\n",
    "    # Validation Set\n",
    "    f':validation_set rdf:type sc:Dataset .',\n",
    "    f':validation_set rdfs:label \"Validation Set\" .',\n",
    "    f':validation_set prov:wasGeneratedBy :define_data_split .',\n",
    "    f':validation_set prov:wasDerivedFrom {input_dataset} .',\n",
    "    f':validation_set rdfs:comment \"Contains xx samples\" .', \n",
    "\n",
    "    # Test Set\n",
    "    f':test_set rdf:type sc:Dataset .',\n",
    "    f':test_set rdfs:label \"Test Set\" .',\n",
    "    f':test_set prov:wasGeneratedBy :define_data_split .',\n",
    "    f':test_set prov:wasDerivedFrom {input_dataset} .',\n",
    "    f':test_set rdfs:comment \"Contains xx samples\" .', \n",
    "\n",
    "    \n",
    "]\n",
    "engine.insert(define_split_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b5ed6-54d6-4c81-9adb-e295fbd5c364",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-978b274ef875c238",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_finetune_model(training_set, validation_set):\n",
    "    # do something here\n",
    "\n",
    "    # Try to automate as much documentation work as possible.\n",
    "    # Define your training runs with their respective hyperparameter settings, etc.\n",
    "    # Document each time a training run, model, its hp_settings, evaluations, ...  \n",
    "    # Create performance figures/graphs\n",
    "\n",
    "    return 'Find most suitable model'\n",
    "\n",
    "\n",
    "start_time_tafm = now()\n",
    "# train_and_finetune_model()\n",
    "end_time_tafm = now() \n",
    "\n",
    "\n",
    "#############################################\n",
    "# Documentation 4d & e & f\n",
    "#############################################\n",
    "\n",
    "tafm_ass_uuid_writer = \"21d60fe3-c9ab-4a0a-bae7-b9fe9653c755\"\n",
    "tafm_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# EXAMPLE output from your training\n",
    "training_run1 = \"run_1\" \n",
    "model_run1 = \"model_run1\"\n",
    "hp1_setting_run1 = \"hp_setting_run1\"\n",
    "eval_train_run1 = \"metric_train_run1\"\n",
    "eval_validation_run1 = \"metric_validation_run1\"\n",
    "\n",
    "\n",
    "train_model_activity = [\n",
    "    # Activity \n",
    "    f':train_and_finetune_model rdf:type prov:Activity .',\n",
    "    f':train_and_finetune_model sc:isPartOf :modeling_phase .',\n",
    "    f':train_and_finetune_model rdfs:comment \"\"\"{tafm_comment}\"\"\" .',\n",
    "    f':train_and_finetune_model prov:startedAtTime \"{start_time_tafm}\"^^xsd:dateTime .',\n",
    "    f':train_and_finetune_model prov:endedAtTime \"{end_time_tafm}\"^^xsd:dateTime .',\n",
    "    f':train_and_finetune_model prov:qualifiedAssociation :{tafm_ass_uuid_writer} .',\n",
    "    f':{tafm_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{tafm_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{tafm_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    ########################################\n",
    "    # ONE model run - automate everything below!\n",
    "\n",
    "    # Parameter settings\n",
    "    f':{hp1_setting_run1} rdf:type mls:HyperParameterSetting .',\n",
    "    f':{hp1_setting_run1} mls:specifiedBy :hp_learning_rate .',\n",
    "    f':{hp1_setting_run1} mls:hasValue \"1.23\"^^xsd:double .',\n",
    "    f':{hp1_setting_run1} prov:wasGeneratedBy :train_and_finetune_model .',\n",
    "    # add your further parameters\n",
    "\n",
    "    # Describe your Run\n",
    "    f':{training_run1} rdf:type mls:Run .',\n",
    "    f':{training_run1} sc:isPartOf :train_and_finetune_model .',\n",
    "    f':{training_run1} mls:realizes :random_forest_algorithm .',\n",
    "    f':{training_run1} rdf:label \"Training Run 1 with...\" .',\n",
    "    f':{training_run1} mls:executes :your_implementation .', \n",
    "    f':{training_run1} mls:hasInput :training_set .',\n",
    "    f':{training_run1} mls:hasInput :validation_set .',\n",
    "    f':{training_run1} mls:hasInput :{hp1_setting_run1} .',     \n",
    "    # list all your used parameters here\n",
    "    f':{training_run1} mls:hasOutput :{model_run1} .',\n",
    "    f':{training_run1} mls:hasOutput :{eval_train_run1} .',\n",
    "    f':{training_run1} mls:hasOutput :{eval_validation_run1} .',\n",
    "\n",
    "    # Describe your Model\n",
    "    f':{model_run1} rdf:type mls:Model .',\n",
    "    f':{model_run1} prov:label \"xxx\" .',\n",
    "    f':{model_run1} prov:wasGeneratedBy :{training_run1} .',\n",
    "    f':{model_run1} mlso:trainedOn :training_set .',\n",
    "    f':{model_run1} mlso:hasAlgorithmType :random_forest_algorithm .',\n",
    "\n",
    "    # Describe your evaluations\n",
    "    # You can have multiple evaluations per model \n",
    "    f':{eval_train_run1} rdf:type mls:ModelEvaluation .',\n",
    "    f':{eval_train_run1} prov:wasGeneratedBy :{training_run1} .',\n",
    "    f':{eval_train_run1} mls:hasValue \"1.23\"^^xsd:double .',\n",
    "    f':{eval_train_run1} mls:specifiedBy :r2_score_measure .',\n",
    "    f':{eval_train_run1} prov:used :training_set .',\n",
    "\n",
    "    f':{eval_validation_run1} rdf:type mls:ModelEvaluation .',\n",
    "    f':{eval_validation_run1} prov:wasGeneratedBy :{training_run1} .',\n",
    "    f':{eval_validation_run1} mls:hasValue \"1.23\"^^xsd:double .',\n",
    "    f':{eval_validation_run1} mls:specifiedBy :r2_score_measure .',\n",
    "    f':{eval_validation_run1} prov:used :validation_set .',\n",
    "\n",
    "    # Dont forget to document any visualizations\n",
    "\n",
    "]\n",
    "engine.insert(train_model_activity, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model_full_data(training_set, validation_set):\n",
    "    \n",
    "    # create your\n",
    "    return \"Final Trained Model\"\n",
    "\n",
    "\n",
    "start_time_tafm = now()\n",
    "# train_and_finetune_model()\n",
    "end_time_tafm = now() \n",
    "\n",
    "\n",
    "#############################################\n",
    "# Documentation 4g\n",
    "#############################################\n",
    "\n",
    "retrain_ass_uuid_writer = \"96815ee0-524c-437b-b5fa-2e15b945c993\" # Generate once\n",
    "\n",
    "final_training_activity = \":retrain_final_model\"\n",
    "final_model = \":final_model_entity\"\n",
    "\n",
    "# Document the retraining activity.\n",
    "# Hint: This activity is still part of the :modeling_phase\n",
    "\n",
    "retrain_documentation = [\n",
    "    # your documentation here    \n",
    "]\n",
    "engine.insert(retrain_documentation, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02059271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06583f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a88bf71f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46137067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Evaluation Phase\n",
    "\n",
    "evaluation_phase_executor = [\n",
    "f':evaluation_phase rdf:type prov:Activity .',\n",
    "f':evaluation_phase rdfs:label \"Evaluation Phase\" .', \n",
    "]\n",
    "engine.insert(evaluation_phase_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d80e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_code_writer = student_b\n",
    "def evaluate_on_test_data(final_model, test_set):\n",
    "\n",
    "    # Predict and evaluation on test data\n",
    "        \n",
    "    return 'Performance'\n",
    "\n",
    "start_time_eval = now()\n",
    "#evaluate_on_test_data()\n",
    "end_time_eval = now() \n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "eval_ass_uuid = \"7f1431e9-feed-429a-92ed-c131b23cbe79\" # Generate once\n",
    "final_model = \":final_model_entity\" \n",
    "test_set = \":test_set\" \n",
    "\n",
    "eval_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "evaluate_activity = [\n",
    "    f':evaluate_final_model rdf:type prov:Activity .',\n",
    "    f':evaluate_final_model sc:isPartOf :evaluation_phase .',\n",
    "    f':evaluate_final_model rdfs:label \"Final Model Evaluation on Test Set\" .',\n",
    "    f':evaluate_final_model rdfs:comment \"\"\"{eval_comment}\"\"\" .',\n",
    "    f':evaluate_final_model prov:startedAtTime \"{start_time_eval}\"^^xsd:dateTime .',\n",
    "    f':evaluate_final_model prov:endedAtTime \"{end_time_eval}\"^^xsd:dateTime .',\n",
    "    f':evaluate_final_model prov:qualifiedAssociation :{eval_ass_uuid} .',\n",
    "    \n",
    "    f':{eval_ass_uuid} prov:agent :{eval_code_writer} .',\n",
    "    f':{eval_ass_uuid} rdf:type prov:Association .',\n",
    "    f':{eval_ass_uuid} prov:hadRole :{code_writer_role} .',\n",
    "\n",
    "    # Inputs\n",
    "    f':evaluate_final_model prov:used {final_model} .',\n",
    "    f':evaluate_final_model prov:used {test_set} .',\n",
    "    \n",
    "    # Reference to Data Mining Success Criteria from Phase 1\n",
    "    f':evaluate_final_model prov:used :bu_data_mining_success_criteria .',\n",
    "\n",
    "    # Document you final model performance\n",
    " \n",
    "    # Hint: you evaluate bias in this way:\n",
    "    f':bias_evaluation_result rdf:type mls:ModelEvaluation .',\n",
    "    f':bias_evaluation_result prov:wasGeneratedBy :evaluate_final_model .',\n",
    "    f':bias_evaluation_result rdfs:label \"Bias Analysis\" .',\n",
    "    f':bias_evaluation_result rdfs:comment \"...\" .',\n",
    "    \n",
    "]\n",
    "engine.insert(evaluate_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785c94b",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ad2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Deployment Phase\n",
    "\n",
    "deployment_phase_executor = [\n",
    "f':deployment_phase rdf:type prov:Activity .',\n",
    "f':deployment_phase rdfs:label \"Deployment Phase\" .', \n",
    "]\n",
    "engine.insert(deployment_phase_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176313c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "comparison_and_recommendations_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "ethical_aspects_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "monitoring_plan_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "reproducibility_reflection_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "dep_ass_uuid_executor = \"72a921e0-1234-4567-89ab-cdef01234567\" # Generate once\n",
    "deployment_executor = [\n",
    "f':plan_deployment rdf:type prov:Activity .',\n",
    "f':plan_deployment sc:isPartOf :deployment_phase .', # Connect to Parent Phase\n",
    "f':plan_deployment rdfs:label \"Plan Deployment\"@en .',\n",
    "\n",
    "f':plan_deployment prov:qualifiedAssociation :{dep_ass_uuid_executor} .',\n",
    "f':{dep_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "f':{dep_ass_uuid_executor} rdf:type prov:Association .',\n",
    "f':{dep_ass_uuid_executor} prov:hadRole :{code_executor_role} .', \n",
    "]\n",
    "engine.insert(deployment_executor, prefixes=prefixes)\n",
    "\n",
    "\n",
    "deployment_data_executor = [\n",
    "#6a\n",
    "f':dep_recommendations rdf:type prov:Entity .',\n",
    "f':dep_recommendations prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_recommendations rdfs:label \"6a Business Objectives Reflection and Deployment Recommendations\" .',\n",
    "f':dep_recommendations rdfs:comment \"\"\"{comparison_and_recommendations_comment}\"\"\" .',\n",
    "#6b\n",
    "f':dep_ethical_risks rdf:type prov:Entity .',\n",
    "f':dep_ethical_risks prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_ethical_risks rdfs:label \"6b Ethical Aspects and Risks\" .',\n",
    "f':dep_ethical_risks rdfs:comment \"\"\"{ethical_aspects_comment}\"\"\" .',\n",
    "#6c\n",
    "f':dep_monitoring_plan rdf:type prov:Entity .',\n",
    "f':dep_monitoring_plan prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_monitoring_plan rdfs:label \"6c Monitoring Plan\" .',\n",
    "f':dep_monitoring_plan rdfs:comment \"\"\"{monitoring_plan_comment}\"\"\" .',\n",
    "#6d\n",
    "f':dep_reproducibility_reflection rdf:type prov:Entity .',\n",
    "f':dep_reproducibility_reflection prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_reproducibility_reflection rdfs:label \"6d Reproducibility Reflection\" .',\n",
    "f':dep_reproducibility_reflection rdfs:comment \"\"\"{reproducibility_reflection_comment}\"\"\" .',\n",
    "\n",
    "]\n",
    "engine.insert(deployment_data_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528dac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d410af",
   "metadata": {},
   "source": [
    "# Generate Latex Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f44e16",
   "metadata": {},
   "source": [
    "The following cells give you an example of how to automatically create a Latex Report from your provenance documentation.\n",
    "\n",
    "Feel free to use the example provided. If you use it, you should adapt and extend it with relevant sections/tables/plots/... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37046b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_iri = f\"https://starvers.ec.tuwien.ac.at/ SOS2025/{group_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell includes cleaning functions\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def latex_escape(text: str | None) -> str:\n",
    "    if text is None: return \"\"\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\\", r\"\\textbackslash{}\")\n",
    "    pairs = [\n",
    "        (\"&\", r\"\\&\"), (\"%\", r\"\\%\"), (\"$\", r\"\\$\"), (\"#\", r\"\\#\"), \n",
    "        (\"_\", r\"\\_\"), (\"{\", r\"\\{\"), (\"}\", r\"\\}\"), \n",
    "        (\"~\", r\"\\textasciitilde{}\"), (\"^\", r\"\\textasciicircum{}\")\n",
    "    ]\n",
    "    for k, v in pairs:\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "\n",
    "def clean_rdf(x) -> str:\n",
    "    if hasattr(x, \"toPython\"): return str(x.toPython())\n",
    "    if x is None: return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.strip('\"').strip(\"'\")\n",
    "    s = s.strip()\n",
    "    if \"^^\" in s:\n",
    "        s = s.split(\"^^\")[0].strip('\"')\n",
    "        \n",
    "    return s\n",
    "\n",
    "def fmt_iso(ts: str) -> str:\n",
    "    if not ts: return \"\"\n",
    "    try:\n",
    "        clean_ts = ts.split(\"^^\")[0].strip('\"')\n",
    "        clean_ts = clean_ts.replace(\"Z\", \"+00:00\") if clean_ts.endswith(\"Z\") else clean_ts\n",
    "        return datetime.fromisoformat(clean_ts).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        return latex_escape(str(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948da2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data ONLY for: https://starvers.ec.tuwien.ac.at/ SOS2025/00/\n",
      "Data extraction done.\n"
     ]
    }
   ],
   "source": [
    "# This cell includes exemplary queries for different phases\n",
    "\n",
    "base_iri = f\"https://starvers.ec.tuwien.ac.at/ SOS2025/{group_id}/\"\n",
    "print(f\"Fetching data ONLY for: {base_iri}\")\n",
    "\n",
    "prefix_header = f\"\"\"\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX prov: <http://www.w3.org/ns/prov#>\n",
    "PREFIX sc: <https://schema.org/>\n",
    "PREFIX cr: <http://mlcommons.org/croissant/>\n",
    "PREFIX mls: <http://www.w3.org/ns/mls#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX : <{base_iri}>\n",
    "\"\"\"\n",
    "\n",
    "### Author Block\n",
    "author_query = f\"\"\"\n",
    "{prefix_header}\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX iao: <http://purl.obolibrary.org/obo/>\n",
    "\n",
    "SELECT DISTINCT ?uri ?given ?family ?matr WHERE {{\n",
    "  VALUES ?uri {{ :{student_a} :{student_b} }}\n",
    "  \n",
    "  ?uri a foaf:Person .\n",
    "  ?uri foaf:givenName ?given .\n",
    "  ?uri foaf:familyName ?family .\n",
    "  ?uri iao:IAO_0000219 ?matr .\n",
    "}}\n",
    "\"\"\"\n",
    "res_authors = engine.query(author_query)\n",
    "author_block_latex = \"\"\n",
    "\n",
    "if not res_authors.empty: # type:ignore\n",
    "    for _, row in res_authors.iterrows(): # type:ignore\n",
    "\n",
    "        uri_str = str(row['uri'])\n",
    "        given = latex_escape(clean_rdf(row['given']))\n",
    "        family = latex_escape(clean_rdf(row['family']))\n",
    "        matr = latex_escape(clean_rdf(row['matr']))\n",
    "        if student_a in uri_str:\n",
    "            responsibility = \"Student A\"\n",
    "        elif student_b in uri_str:\n",
    "            responsibility = \"Student B\"\n",
    "        else:\n",
    "            responsibility = \"Student\"\n",
    "        \n",
    "        author_block_latex += rf\"\"\"\n",
    "          \\author{{{given} {family}}}\n",
    "          \\authornote{{{responsibility}, Matr.Nr.: {matr}}}\n",
    "          \\affiliation{{\n",
    "            \\institution{{TU Wien}}\n",
    "            \\country{{Austria}}\n",
    "          }}\n",
    "          \"\"\"\n",
    "\n",
    "### Business Understanding example\n",
    "bu_query = f\"\"\"\n",
    "{prefix_header}\n",
    "SELECT ?ds_comment ?bo_comment WHERE {{\n",
    "  OPTIONAL {{ :bu_data_source_and_scenario rdfs:comment ?ds_comment . }}\n",
    "  OPTIONAL {{ :bu_business_objectives rdfs:comment ?bo_comment . }}\n",
    "}} LIMIT 1\n",
    "\"\"\"\n",
    "res_bu = engine.query(bu_query)\n",
    "row_bu = res_bu.iloc[0] if not res_bu.empty else {} # type:ignore\n",
    "bu_data_source = latex_escape(clean_rdf(row_bu.get(\"ds_comment\", \"\")))\n",
    "bu_objectives  = latex_escape(clean_rdf(row_bu.get(\"bo_comment\", \"\")))\n",
    "\n",
    "\n",
    "### Data Understanding examples\n",
    "# Example Dataset Description\n",
    "du_desc_query = f\"\"\"\n",
    "{prefix_header}\n",
    "SELECT ?desc WHERE {{ :raw_data sc:description ?desc . }} LIMIT 1\n",
    "\"\"\"\n",
    "res_du_desc = engine.query(du_desc_query)\n",
    "row_du_desc = res_du_desc.iloc[0] if not res_du_desc.empty else {} # type:ignore\n",
    "du_description = latex_escape(clean_rdf(row_du_desc.get(\"desc\", \"\")))\n",
    "\n",
    "# Example Feature Columns Table\n",
    "du_query = f\"\"\"\n",
    "{prefix_header}\n",
    "SELECT ?name (SAMPLE(?dtypeRaw) as ?dtype) (SAMPLE(?descRaw) as ?desc) WHERE {{\n",
    "  :raw_data cr:recordSet ?rs .\n",
    "  ?rs cr:field ?field .\n",
    "  ?field sc:name ?name .\n",
    "  ?field sc:description ?descRaw .\n",
    "  ?field cr:dataType ?dtypeRaw .\n",
    "}} \n",
    "GROUP BY ?name\n",
    "ORDER BY ?name\n",
    "\"\"\"\n",
    "res_du = engine.query(du_query)\n",
    "du_rows = []\n",
    "if not res_du.empty: # type:ignore\n",
    "    for _, f in res_du.iterrows(): # type:ignore\n",
    "        dtype_raw = clean_rdf(f.get(\"dtype\", \"\"))\n",
    "        if '#' in dtype_raw: dtype = dtype_raw.split('#')[-1]\n",
    "        elif '/' in dtype_raw: dtype = dtype_raw.split('/')[-1]\n",
    "        else: dtype = dtype_raw\n",
    "        \n",
    "        desc = clean_rdf(f.get(\"desc\", \"\"))\n",
    "        row_str = f\"{latex_escape(clean_rdf(f['name']))} & {latex_escape(dtype)} & {latex_escape(desc)} \\\\\\\\\"\n",
    "        du_rows.append(row_str)\n",
    "du_table_rows = \"\\n    \".join(du_rows)\n",
    "\n",
    "### Modeling example\n",
    "# Hyperparameters\n",
    "hp_query = f\"\"\"\n",
    "{prefix_header}\n",
    "SELECT ?hpName (SAMPLE(?hpValRaw) as ?hpVal) (MAX(?hpDescRaw) as ?hpDesc) WHERE {{\n",
    "  ?run sc:isPartOf :train_and_finetune_model .\n",
    "  ?run mls:hasInput ?setting .\n",
    "  ?setting a mls:HyperParameterSetting .\n",
    "  ?setting mls:hasValue ?hpValRaw .\n",
    "  ?setting mls:specifiedBy ?hpDef .\n",
    "  ?hpDef rdfs:label ?hpName .\n",
    "  OPTIONAL {{ ?hpDef rdfs:comment ?hpDescRaw . }}\n",
    "}} \n",
    "GROUP BY ?hpName\n",
    "ORDER BY ?hpName\n",
    "\"\"\"\n",
    "res_hp = engine.query(hp_query)\n",
    "hp_rows = []\n",
    "if not res_hp.empty: #type:ignore\n",
    "    for _, row in res_hp.iterrows(): #type:ignore\n",
    "        name = latex_escape(clean_rdf(row['hpName']))\n",
    "        val  = latex_escape(clean_rdf(row['hpVal']))\n",
    "        desc = latex_escape(clean_rdf(row.get('hpDesc', '')))\n",
    "        hp_rows.append(rf\"{name} & {desc} & {val} \\\\\")\n",
    "\n",
    "hp_table_rows = \"\\n    \".join(hp_rows)\n",
    "\n",
    "# Run Info\n",
    "run_query = f\"\"\"\n",
    "{prefix_header}\n",
    "SELECT ?algoLabel ?start ?end ?metricLabel ?metricVal WHERE {{\n",
    "  OPTIONAL {{ :train_and_finetune_model prov:startedAtTime ?start ; prov:endedAtTime ?end . }}\n",
    "  OPTIONAL {{\n",
    "      ?run sc:isPartOf :train_and_finetune_model .\n",
    "      ?run mls:realizes ?algo .\n",
    "      ?algo rdfs:label ?algoLabel .\n",
    "  }}\n",
    "  OPTIONAL {{\n",
    "    ?run sc:isPartOf :train_and_finetune_model .\n",
    "    ?run mls:hasOutput ?eval .\n",
    "    ?eval a mls:ModelEvaluation ; mls:hasValue ?metricVal .\n",
    "    OPTIONAL {{ ?eval mls:specifiedBy ?m . ?m rdfs:label ?metricLabel . }}\n",
    "  }}\n",
    "}} LIMIT 1\n",
    "\"\"\"\n",
    "res_run = engine.query(run_query)\n",
    "row_run = res_run.iloc[0] if not res_run.empty else {} #type:ignore\n",
    "mod_algo  = latex_escape(clean_rdf(row_run.get(\"algoLabel\", \"\")))\n",
    "mod_start = latex_escape(fmt_iso(clean_rdf(row_run.get(\"start\"))))\n",
    "mod_end   = latex_escape(fmt_iso(clean_rdf(row_run.get(\"end\"))))\n",
    "mod_m_lbl = latex_escape(clean_rdf(row_run.get(\"metricLabel\", \"\")))\n",
    "raw_val = clean_rdf(row_run.get('metricVal', ''))\n",
    "mod_m_val = f\"{float(raw_val):.4f}\" if raw_val else \"\"\n",
    "\n",
    "print(\"Data extraction done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8fa1c",
   "metadata": {},
   "source": [
    "The following includes the Latex report itself. It fills in the query-results from the cell before. The ACM Template is already filled. \n",
    "Make sure that you update Student A and B accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ce52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_content = rf\"\"\"\\documentclass[sigconf]{{acmart}}\n",
    "\n",
    "\\AtBeginDocument{{ \\providecommand\\BibTeX{{ Bib\\TeX }} }}\n",
    "\\setcopyright{{acmlicensed}}\n",
    "\\copyrightyear{{2025}}\n",
    "\\acmYear{{2025}}\n",
    "\\acmDOI{{XXXXXXX.XXXXXXX}}\n",
    "\n",
    "\\acmConference[BI 2025]{{Business Intelligence}}{{-}}{{-}}\n",
    "\n",
    "\\begin{{document}}\n",
    "\n",
    "\\title{{ SOS2025 Experiment Report - Group {group_id}}}\n",
    "%% ---Authors: Dynamically added ---\n",
    "{author_block_latex}\n",
    "\n",
    "\\begin{{abstract}}\n",
    "  This report documents the machine learning experiment for Group {group_id}, following the CRISP-DM process model.\n",
    "\\end{{abstract}}\n",
    "\n",
    "\\ccsdesc[500]{{Computing methodologies~Machine learning}}\n",
    "\\keywords{{CRISP-DM, Provenance, Knowledge Graph, Machine Learning}}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "%% --- 1. Business Understanding ---\n",
    "\\section{{Business Understanding}}\n",
    "\n",
    "\\subsection{{Data Source and Scenario}}\n",
    "{bu_data_source}\n",
    "\n",
    "\\subsection{{Business Objectives}}\n",
    "{bu_objectives}\n",
    "\n",
    "%% --- 2. Data Understanding ---\n",
    "\\section{{Data Understanding}}\n",
    "\\textbf{{Dataset Description:}} {du_description}\n",
    "\n",
    "The following features were identified in the dataset:\n",
    "\n",
    "\\begin{{table}}[h]\n",
    "  \\caption{{Raw Data Features}}\n",
    "  \\label{{tab:features}}\n",
    "  \\begin{{tabular}}{{lp{{0.2\\linewidth}}p{{0.4\\linewidth}}}}\n",
    "    \\toprule\n",
    "    \\textbf{{Feature Name}} & \\textbf{{Data Type}} & \\textbf{{Description}} \\\\\n",
    "    \\midrule\n",
    "    {du_table_rows}\n",
    "    \\bottomrule\n",
    "  \\end{{tabular}}\n",
    "\\end{{table}}\n",
    "\n",
    "%% --- 3. Data Preparation ---\n",
    "\\section{{Data Preparation}}\n",
    "\\subsection{{Data Cleaning}}\n",
    "Describe your Data preparation steps here and include respective graph data.\n",
    "\n",
    "\n",
    "%% --- 4. Modeling ---\n",
    "\\section{{Modeling}}\n",
    "\n",
    "\\subsection{{Hyperparameter Configuration}}\n",
    "The model was trained using the following hyperparameter settings:\n",
    "\n",
    "\\begin{{table}}[h]\n",
    "  \\caption{{Hyperparameter Settings}}\n",
    "  \\label{{tab:hyperparams}}\n",
    "  \\begin{{tabular}}{{lp{{0.4\\linewidth}}l}}\n",
    "    \\toprule\n",
    "    \\textbf{{Parameter}} & \\textbf{{Description}} & \\textbf{{Value}} \\\\\n",
    "    \\midrule\n",
    "    {hp_table_rows}\n",
    "    \\bottomrule\n",
    "  \\end{{tabular}}\n",
    "\\end{{table}}\n",
    "\n",
    "\\subsection{{Training Run}}\n",
    "A training run was executed with the following characteristics:\n",
    "\\begin{{itemize}}\n",
    "    \\item \\textbf{{Algorithm:}} {mod_algo}\n",
    "    \\item \\textbf{{Start Time:}} {mod_start}\n",
    "    \\item \\textbf{{End Time:}} {mod_end}\n",
    "    \\item \\textbf{{Result:}} {mod_m_lbl} = {mod_m_val}\n",
    "\\end{{itemize}}\n",
    "\n",
    "%% --- 5. Evaluation ---\n",
    "\\section{{Evaluation}}\n",
    "\n",
    "%% --- 6. Deployment ---\n",
    "\\section{{Deployment}}\n",
    "\n",
    "\\section{{Conclusion}}\n",
    "\n",
    "\\end{{document}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c947b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report written to: data/report/experiment_report.tex\n"
     ]
    }
   ],
   "source": [
    "# This cell stores the Latex report to the data/report directory\n",
    "\n",
    "out_dir = os.path.join(\"data\", \"report\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"experiment_report.tex\")\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_content)\n",
    "\n",
    "print(f\"Report written to: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "41f73c966b043d9e7235520aa316ee35e88afc7f8f981a58dcb407e561ce5f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
