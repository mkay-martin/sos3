{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f7d15c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5122654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import typing\n",
    "import requests\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from starvers.starvers import TripleStoreEngine\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "import json\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, BNode\n",
    "from rdflib.namespace import RDF, RDFS, XSD, DCTERMS\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def now() -> str:\n",
    "    \"\"\"\n",
    "    Returns the current time in ISO 8601 format with UTC timezone in the following format:\n",
    "    YYYY-MM-DDTHH:MM:SS.sssZ\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now(datetime.timezone.utc)\n",
    "    timestamp_formated = timestamp.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]  +\"Z\"\n",
    "\n",
    "    return timestamp_formated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae9b28",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the Data Frame\n",
    "\n",
    "dataset_path = \"\" # File has to be in the same directory as the notebook\n",
    "file_name = 'php0FyS2T.arff' # Filename in .arff format \n",
    "\n",
    "def load_arff_data() -> pd.DataFrame:\n",
    "    \n",
    "    input_file = os.path.join(dataset_path, file_name) \n",
    "    \n",
    "    # Use scipy's arff loader to handle the @attribute metadata and @data sections\n",
    "    raw_data, meta = arff.loadarff(input_file)\n",
    "    \n",
    "    # Convert the raw structured array to a pandas DataFrame\n",
    "    dataframe = pd.DataFrame(raw_data)\n",
    "\n",
    "    def clean_data(df: pd.DataFrame):\n",
    "        # ARFF loaders often read nominal/string attributes as bytes (e.g., b'1').\n",
    "        # This function decodes them back to standard strings or integers.\n",
    "        if 'Class' in df.columns and df['Class'].dtype == object: # Convert original string values (in case they were wrongly importated as \"byte\") back to to string or integer\n",
    "             df['Class'] = df['Class'].str.decode('utf-8').astype(int)\n",
    "        return df\n",
    "\n",
    "    loaded_data = dataframe\n",
    "    loaded_data = clean_data(loaded_data)\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "# Execute\n",
    "df = load_arff_data()\n",
    "\n",
    "display(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "\n",
    "def analyze_dataset(df: pd.DataFrame):\n",
    "    print(\"=== Dataset Overview ===\")\n",
    "    n_instances, n_attributes = df.shape\n",
    "    print(f\"Number of instances: {n_instances}\")\n",
    "    print(f\"Number of attributes: {n_attributes}\")\n",
    "    \n",
    "    # Check for Class attribute\n",
    "    if 'Class' not in df.columns:\n",
    "        target_col = df.columns[-1]  # Sometimes the target is the last column with a different name\n",
    "        print(f\"Target column assumed to be: '{target_col}'\")\n",
    "    else:\n",
    "        target_col = 'Class'\n",
    "        \n",
    "    print(f\"\\n=== Attribute Types ===\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    print(\"\\n=== Missing Values ===\")\n",
    "    missing_counts = df.isnull().sum()\n",
    "    total_missing = missing_counts.sum()\n",
    "    print(f\"Total missing values: {total_missing}\")\n",
    "    if total_missing > 0:\n",
    "        print(missing_counts[missing_counts > 0])\n",
    "        \n",
    "    print(\"\\n=== Value Ranges & Statistics ===\")\n",
    "    # numeric_df excludes the target if it's categorical\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    stats = numeric_df.describe().T\n",
    "    stats['range'] = stats['max'] - stats['min']\n",
    "    display(stats[['min', 'max', 'mean', 'std', 'range']].head())\n",
    "\n",
    "    print(\"\\n=== Sparsity ===\")\n",
    "    zero_counts = (numeric_df == 0).sum().sum()\n",
    "    total_cells = numeric_df.size\n",
    "    sparsity = zero_counts / total_cells\n",
    "    print(f\"Sparsity (percentage of zeros): {sparsity:.2%}\")\n",
    "\n",
    "    print(\"\\n=== Class Distribution (Majority/Minority) ===\")\n",
    "    class_counts = df[target_col].value_counts()\n",
    "    print(f\"Number of classes: {len(class_counts)}\")\n",
    "    print(f\"Min class size: {class_counts.min()}\")\n",
    "    print(f\"Max class size: {class_counts.max()}\")\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # 1. Class Distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Using a subset if too many classes\n",
    "    if len(class_counts) > 20:\n",
    "        sns.histplot(class_counts, bins=10, kde=False)\n",
    "        plt.title('Histogram of Class Sizes')\n",
    "        plt.xlabel('Number of Instances per Class')\n",
    "    else:\n",
    "        sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "        plt.title('Class Distribution')\n",
    "        \n",
    "    # 2. Correlation Matrix (features only)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Subsampling features if too many for a clean plot\n",
    "    corr_matrix = numeric_df.iloc[:, :20].corr() \n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title('Correlation Matrix (First 20 Features)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return stats, class_counts\n",
    "\n",
    "# Execute Analysis\n",
    "stats, class_counts = analyze_dataset(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080c51d",
   "metadata": {},
   "source": [
    "## TASK 1 (Train a regular SOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b4793-5fad-4c9a-89dd-abd662f916b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781e016-c770-43d2-871a-f4f4ab7378b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "41f73c966b043d9e7235520aa316ee35e88afc7f8f981a58dcb407e561ce5f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
